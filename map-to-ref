#!/usr/bin/env python3

import os
os.environ['ANSIBLE_FORCE_COLOR'] = "TRUE"
import sys
import platform
import argparse
import logging
import subprocess
import re
from pathlib import Path
import datetime
import glob
import time
import GPUtil
import pandas as pd
import shutil
import gzip


# def make_stats(fast_file):
#     stat_file = fast_file.split('.')[0] + '-stats.txt'
#     cmd = "seqkit stats " + fast_file +" > " +stat_file
#     # print(cmd)
#     subprocess.run(cmd, shell=True)
#     return stat_file


def getref(inRef, db):
  files = []
  for ref in inRef:
    file = glob.glob(ref+'*')
    if not ".fasta" in file or not file:
      cmd = 'blastdbcmd -entry '+ ref +' -db '+ db +' -out '+ outdir + '/'+ref+'.fasta'
      subprocess.run(cmd, shell=True)
      files.append(outdir + '/'+ref+'.fasta')
    else:
      files.append(file)
  return files

# def maptoref(ref)


def main():


  parser = argparse.ArgumentParser(prog='maptoref', 
    description='Generates stats for a map to reference', 
    formatter_class=lambda prog: argparse.HelpFormatter(prog,max_help_position=30,width=200))
  requiredArgs = parser.add_argument_group('Required arguments')
  requiredArgs.add_argument('-i', '--input', action='store', dest='fastq', nargs='*',type=str, metavar='DIR', help='Input fastq files')
  requiredArgs.add_argument('-o', '--output', action='store', dest='outdir', type=str, metavar='DIR', help='Output directory | default: '+home+'/Desktop/NGS-data', default=home+'/Desktop/NGS-data')
  requiredArgs.add_argument('-m', '--ref','--manualRef', action='store', type=str, dest='manualRef', nargs='*', help='Manual mapping to custom reference')

  # requiredArgs.add_argument('-r', '--runid', action='store', dest='runid', type=str, required=True, metavar='RUNID')
  optionalArgs = parser.add_argument_group('Optional arguments')
  requiredArgs.add_argument('-i', '--input', action='store', dest='fastqDir', nargs='*',type=str, metavar='DIR', help='Input directory with basecalled fastq files | default: '+home+'/Desktop/NGS-data', default=home+'/Desktop/NGS-data')
  requiredArgs.add_argument('-o', '--output', action='store', dest='outputFolder', type=str, metavar='DIR', help='Output directory | default: '+home+'/Desktop/NGS-data', default=home+'/Desktop/NGS-data')
  requiredArgs.add_argument('-m', '--ref','--manualRef', action='store', type=str, dest='refs', nargs='*', help='Manual mapping to custom reference')
  optionalArgs.add_argument('-db', '--db', action='store', dest='db', type=str, metavar='DIR', help='Database directory | default: '+home+'/Desktop/NGS-scripts/DB', default=home+'/Desktop/NGS-scripts/DB/ALL.fasta')
  optionalArgs.add_argument('-l','--label', action='store', dest='label', type=str, metavar='STR', help='Label the analysis run with extra info if planning to run several times', default='')
  optionalArgs.add_argument('-cov','-covLimit', action='store', dest='covLimit', nargs='*', type=str, metavar='INT', help='Coverage limit for calling a consensus base', default=[20])
  optionalArgs.add_argument('-t', '--threads', action='store', dest='threads', type=int, metavar='INT', help='Number of threads | default: 4', default=4)

  scriptPath = os.path.dirname(os.path.abspath(__file__))
  inputArgs = parser.parse_args()


  logFormatter = logging.Formatter('%(levelname)s\t%(asctime)s\t%(message)s', datefmt='%I:%M:%S %d.%m.%Y')
  logger = logging.getLogger()

  analysis_log_file = outdir + '/map-to-ref-' +fastq+ '-'+('-').join(inputArgs.refs)+'.log'
  fileHandler = logging.FileHandler(analysis_log_file)
  fileHandler.setFormatter(logFormatter)
  logger.addHandler(fileHandler)

  consoleHandler = logging.StreamHandler(sys.stdout)
  consoleHandler.setFormatter(logFormatter)
  logger.addHandler(consoleHandler)
  logger.setLevel(logging.DEBUG)

  refs = getref(inputArgs.refs, inputArgs.db)
  print(refs)

  exit()
  consensus_command = 'snakemake --snakefile '+scriptPath+'/map-to-ref.snakefile \
  --config fastq=' + inputArgs.fastq + 'refs=' + refs + 'db=' + inputArgs.db + ' --use-conda --conda-prefix '+home+'/opt/iflow \
  --cores '+ str(inputArgs.threads) 
  with subprocess.Popen(consensus_command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell = True,bufsize=1, universal_newlines=True) as p:
      for line in p.stdout:
          logger.info(line.rstrip()) 







if __name__ == "__main__":
    main()







with open(ANALYSIS_FOLDER+'/config.yaml', 'w') as f:
  f.write('runid: ' + RUNID + '\n')
  f.write('table: ' + ANALYSIS_FOLDER + '/table.csv\n')
  f.write('data: ' + str(inputArgs.fastqDir) + '\n')
  f.write('db: ' + inputArgs.db + '\n')
  f.write('script_path: ' + scriptPath + '\n')
  f.write('covLimit: '+ str(inputArgs.covLimit)+ '\n')
  if (inputArgs.manualRef):
    f.write('manual_ref: ' + (',').join(inputArgs.manualRef)+ '\n')
  f.write('label: ' + inputArgs.label + '\n')
  f.write('runidwolabel: ' + inputArgs.runid + '\n')
  f.write('CompletionDay: '+ str(nowTimeDay)+ '\n')
  f.write('CommonViruses: '+ scriptPath +'/common-viruses.txt\n')



  



  consensus_command = 'snakemake --snakefile '+scriptPath+'/06.consensusC.merge.snakefile \
  --configfile '+ANALYSIS_FOLDER+'/config.yaml --config blastlist='+ANALYSIS_FOLDER + '/' + RUNID + '_RESULTS/'+RUNID+'-all-blasted-list.csv steps='+cleanOpts+' \
  --cores '+ str(inputArgs.threads) 

  with subprocess.Popen(consensus_command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell = True,bufsize=1, universal_newlines=True) as p:
    for line in p.stdout:
      logger.info(line.rstrip()) 